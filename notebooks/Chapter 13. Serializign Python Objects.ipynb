{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Diving In\n",
    "\n",
    "Serializing enable saving an reloading of an in-memory data structure. The data is only meant to be used by the same program that created it, therefore the interoperability issues are limited to ensuring that later versions of the program can read data written by earlier versions.\n",
    "\n",
    "For cases like this, the `pickle` module in python is ideal.\n",
    "\n",
    "What can `pickle` module store?\n",
    "\n",
    "* All the native data types: booleans, integers, floating point numbers, complex numbers, strings, bytes objects, arrays and None\n",
    "* Lists tuples, dictionaries and sets containing any combination of native data types\n",
    "* Lists, tuples, dictionaries and sets containing any combination of lists, tuples, dictionaries and sets containing any combination of native data types (and so on, to the maximum nesting level that Python supports).\n",
    "* functions, classes and instances of classes (with caveats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Saving data to a pickle file.\n",
    "\n",
    "The `pickle` module works with data structures, let's build one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Dive into history, 2009 edition',\n",
       " 'article_link': 'http://diveintomark.org/archives/2009/03/27/dive-into-history-2009-edition',\n",
       " 'comments_link': None,\n",
       " 'internal_id': b'\\xde\\xd5\\xb4\\xf8',\n",
       " 'tags': ('diveintopython', 'docbook', 'html'),\n",
       " 'published': True,\n",
       " 'published_date': datetime.datetime(2006, 11, 21, 16, 30)}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entry = {}\n",
    "entry['title'] = 'Dive into history, 2009 edition'\n",
    "entry['article_link'] = 'http://diveintomark.org/archives/2009/03/27/dive-into-history-2009-edition'\n",
    "entry['comments_link'] = None\n",
    "entry['internal_id'] = b'\\xDE\\xD5\\xB4\\xF8'\n",
    "entry['tags'] = ('diveintopython', 'docbook', 'html')\n",
    "entry['published'] = True\n",
    "\n",
    "from datetime import datetime\n",
    "entry['published_date'] = datetime.strptime('21/11/06 16:30', \"%d/%m/%y %H:%M\")\n",
    "entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving entry dictionary to file\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "print(\"Saving entry dictionary to file\")\n",
    "\n",
    "with open('examples/entry.pickle', 'wb') as f:\n",
    "    pickle.dump(entry, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `dump` function in `pickle` modules takes a serializable python data structure and serializes it into a binary format using the latest version of the pickle protocol and saves it to an open file.\n",
    "\n",
    "* The `pickle` module takes a python data structure and saves it to a file\n",
    "* To do this, it serializes the data structure using a data format called the pickle protocol\n",
    "* The pickle protocol is python specific. there is no cross languages compatibility\n",
    "* Not every python data structure can be serialized by the `pickle` module. The pickle protocol has changed several times as new data types have been added to Python langues, but there are still limitations.\n",
    "* As a result of these changes, ther eis no guarantee of compatility between versions. Newer versions of Python support the older serialization formats, but older versions do not support newer versions.\n",
    "* Unless otherwise specified the functions in the `pickle` module will use the latest version of the protocol.\n",
    "* The latest version of the protocol is a binary format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loading data from a pickle file\n",
    "\n",
    "Lets load data from the pickle file - start by clearing entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "del entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('examples/entry.pickle', 'rb') as f:\n",
    "    entry = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Dive into history, 2009 edition',\n",
       " 'article_link': 'http://diveintomark.org/archives/2009/03/27/dive-into-history-2009-edition',\n",
       " 'comments_link': None,\n",
       " 'internal_id': b'\\xde\\xd5\\xb4\\xf8',\n",
       " 'tags': ('diveintopython', 'docbook', 'html'),\n",
       " 'published': True,\n",
       " 'published_date': datetime.datetime(2006, 11, 21, 16, 30)}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pickle.dump()/pickle.load()` cycle results in a new data structure that is equal to the original data structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pickling without a file\n",
    "\n",
    "The examples earlier showed how to serialize to a Python object directly to a file on disk. But what if you don't want or need a file? You can also serialize to a bytes object in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bytes"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = pickle.dumps(entry)\n",
    "type(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entry2 = pickle.loads(b)\n",
    "entry2 == entry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bytes and String when pickling\n",
    "\n",
    "The pickle protocol has been around for many years. There are now four different versions of the protocol.\n",
    "\n",
    "* Python 1.x had two version of the protocol, a text and a binary version\n",
    "* Python 2.3 introduced version 2 to handle new functionality in class objects. It is a binary format\n",
    "* POython 3.0 introduced another pickle protocol with explicit support for `byte` objects and `byte` arrays. It is binary format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Debugging pickle files.\n",
    "\n",
    "Pickle protocol is binary, attempting to `cat` a pickle file will result is unprintable characters, it's not helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0: \\x80 PROTO      4\n",
      "    2: \\x95 FRAME      291\n",
      "   11: }    EMPTY_DICT\n",
      "   12: \\x94 MEMOIZE    (as 0)\n",
      "   13: (    MARK\n",
      "   14: \\x8c     SHORT_BINUNICODE 'title'\n",
      "   21: \\x94     MEMOIZE    (as 1)\n",
      "   22: \\x8c     SHORT_BINUNICODE 'Dive into history, 2009 edition'\n",
      "   55: \\x94     MEMOIZE    (as 2)\n",
      "   56: \\x8c     SHORT_BINUNICODE 'article_link'\n",
      "   70: \\x94     MEMOIZE    (as 3)\n",
      "   71: \\x8c     SHORT_BINUNICODE 'http://diveintomark.org/archives/2009/03/27/dive-into-history-2009-edition'\n",
      "  147: \\x94     MEMOIZE    (as 4)\n",
      "  148: \\x8c     SHORT_BINUNICODE 'comments_link'\n",
      "  163: \\x94     MEMOIZE    (as 5)\n",
      "  164: N        NONE\n",
      "  165: \\x8c     SHORT_BINUNICODE 'internal_id'\n",
      "  178: \\x94     MEMOIZE    (as 6)\n",
      "  179: C        SHORT_BINBYTES b'\\xde\\xd5\\xb4\\xf8'\n",
      "  185: \\x94     MEMOIZE    (as 7)\n",
      "  186: \\x8c     SHORT_BINUNICODE 'tags'\n",
      "  192: \\x94     MEMOIZE    (as 8)\n",
      "  193: \\x8c     SHORT_BINUNICODE 'diveintopython'\n",
      "  209: \\x94     MEMOIZE    (as 9)\n",
      "  210: \\x8c     SHORT_BINUNICODE 'docbook'\n",
      "  219: \\x94     MEMOIZE    (as 10)\n",
      "  220: \\x8c     SHORT_BINUNICODE 'html'\n",
      "  226: \\x94     MEMOIZE    (as 11)\n",
      "  227: \\x87     TUPLE3\n",
      "  228: \\x94     MEMOIZE    (as 12)\n",
      "  229: \\x8c     SHORT_BINUNICODE 'published'\n",
      "  240: \\x94     MEMOIZE    (as 13)\n",
      "  241: \\x88     NEWTRUE\n",
      "  242: \\x8c     SHORT_BINUNICODE 'published_date'\n",
      "  258: \\x94     MEMOIZE    (as 14)\n",
      "  259: \\x8c     SHORT_BINUNICODE 'datetime'\n",
      "  269: \\x94     MEMOIZE    (as 15)\n",
      "  270: \\x8c     SHORT_BINUNICODE 'datetime'\n",
      "  280: \\x94     MEMOIZE    (as 16)\n",
      "  281: \\x93     STACK_GLOBAL\n",
      "  282: \\x94     MEMOIZE    (as 17)\n",
      "  283: C        SHORT_BINBYTES b'\\x07\\xd6\\x0b\\x15\\x10\\x1e\\x00\\x00\\x00\\x00'\n",
      "  295: \\x94     MEMOIZE    (as 18)\n",
      "  296: \\x85     TUPLE1\n",
      "  297: \\x94     MEMOIZE    (as 19)\n",
      "  298: R        REDUCE\n",
      "  299: \\x94     MEMOIZE    (as 20)\n",
      "  300: u        SETITEMS   (MARK at 13)\n",
      "  301: .    STOP\n",
      "highest protocol among opcodes = 4\n"
     ]
    }
   ],
   "source": [
    "import pickletools\n",
    "\n",
    "with open('examples/entry.pickle', 'rb') as f:\n",
    "    pickletools.dis(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most interesting information in that disassembly is on the last line, because it include the version of pickle with which the file was ssaved. To determine the protocol version used to store a pickle file, you need to look at the markers (\"opcodes\") within the pickled data and use hard coded knowledge of which opcodes were intorduced with each version of the protocol.\n",
    "\n",
    "The `pickletools.dis()` function does exactly that, and it prints the result in the ast line of the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickletools\n",
    "\n",
    "def protocol_version(file_object):\n",
    "    maxproto = 1\n",
    "    for opcode, arg, pos in pickletools.genops(file_object):\n",
    "        maxproto = max(maxproto, opcode.proto)\n",
    "        \n",
    "    return maxproto\n",
    "\n",
    "with open('examples/entry.pickle', 'rb') as f:\n",
    "    v = protocol_version(f)\n",
    "    \n",
    "v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Serializing Python Objects to be read by other languages\n",
    "\n",
    "The data format used by the `pickel` module if python specific. If cross-language compatibility is one of the requirements, one needs to look at other formats. One such format is `JSON`.\n",
    "\n",
    "Python includes a `json` module in the standard library. Like the `pickle` module the `json` module has functions for serializing data structures, but with some important differences.\n",
    "\n",
    "First of all `JSON` data format is text-based, not binary. For example a boolean value is stored as either the character string `false` or `true`. All json values are case-sensitive.\n",
    "\n",
    "JSON allows arbitrary amounts of whitespace between values. This whitespace is insignificant which means json encodes can add as much or as little whitespace as they like, and json decoders are required to ignore the whitespace.\n",
    "\n",
    "There is the perennial problem of character encoding. JSON must be stored as unicode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Saving data to JSON file\n",
    "\n",
    "JSON looks remarkably similar to a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Dive into history, 2009 edition',\n",
       " 'article_link': 'http://diveintomark.org/archives/2009/03/27/dive-into-history-2009-edition',\n",
       " 'comments_link': None,\n",
       " 'internal_id': b'\\xde\\xd5\\xb4\\xf8',\n",
       " 'tags': ('diveintopython', 'docbook', 'html'),\n",
       " 'published': True,\n",
       " 'published_date': datetime.datetime(2006, 11, 21, 16, 30)}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "basic_entry = {}\n",
    "basic_entry['id'] = 256\n",
    "basic_entry['title'] = 'Dive into history, 2009 edition'\n",
    "basic_entry['tags'] = ('diveintopython', 'docbook', 'html')\n",
    "basic_entry['published'] = True\n",
    "basic_entry['comments_link'] = None\n",
    "\n",
    "with open('examples/basic.json', 'w') as f:\n",
    "    json.dump(basic_entry, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"id\": 256, \"title\": \"Dive into history, 2009 edition\", \"tags\": [\"diveintopython\", \"docbook\", \"html\"], \"published\": true, \"comments_link\": null}\n"
     ]
    }
   ],
   "source": [
    "with open('examples/basic.json', 'r') as f:\n",
    "    for line in f:\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JSON is more readable than the `pickle` format. Lets indent the json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('examples/basic-pretty.json', 'w') as f:\n",
    "    json.dump(basic_entry, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": 256,\n",
      "  \"title\": \"Dive into history, 2009 edition\",\n",
      "  \"tags\": [\n",
      "    \"diveintopython\",\n",
      "    \"docbook\",\n",
      "    \"html\"\n",
      "  ],\n",
      "  \"published\": true,\n",
      "  \"comments_link\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "with open('examples/basic-pretty.json', 'r') as f:\n",
    "    for line in f:\n",
    "        print(line.rstrip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Mapping of Python DataTypes to JSON\n",
    "\n",
    "Since JSON is not python specific there are some mismatches in its coverage of python data types. Some of them are simply naming differences, but there is two important data types that are missing\n",
    "\n",
    "* bytes\n",
    "* Tuple\n",
    "\n",
    "JSON has an array type, which the `json` module maps to Python list, but it does not have a seperate type for tuples. And while JSON has support for string, it has not support for `bytes` (objects and arrays)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Serializing unsupported data types by JSON\n",
    "\n",
    "The JSON module provides extensibility hooks for encoding and decoding unknown datatypes. Lets take a look at some examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Dive into history, 2009 edition',\n",
       " 'article_link': 'http://diveintomark.org/archives/2009/03/27/dive-into-history-2009-edition',\n",
       " 'comments_link': None,\n",
       " 'internal_id': b'\\xde\\xd5\\xb4\\xf8',\n",
       " 'tags': ('diveintopython', 'docbook', 'html'),\n",
       " 'published': True,\n",
       " 'published_date': datetime.datetime(2006, 11, 21, 16, 30)}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def to_json(pobject):\n",
    "    if isinstance(pobject, bytes):\n",
    "        print('Serializing bytes')\n",
    "        return { '__class__':  'bytes', '__value__': list(pobject)}\n",
    "    \n",
    "    if isinstance(pobject, datetime):\n",
    "        print('Serializing datetime')\n",
    "        return {'__class__' : 'datetime.asctime',\n",
    "                '__value__': pobject.strftime('%d/%m/%y %H:%M')}\n",
    "    \n",
    "    print(f'No custom for type {type(pobject)}')\n",
    "\n",
    "    raise TypeError(repr(pobject) + ' is not JSON serializable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serializing bytes\n",
      "Serializing datetime\n"
     ]
    }
   ],
   "source": [
    "with open('examples/entry.json', 'w') as f:\n",
    "    json.dump(entry, f, default=to_json, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"title\": \"Dive into history, 2009 edition\",\n",
      "  \"article_link\": \"http://diveintomark.org/archives/2009/03/27/dive-into-history-2009-edition\",\n",
      "  \"comments_link\": null,\n",
      "  \"internal_id\": {\n",
      "    \"__class__\": \"bytes\",\n",
      "    \"__value__\": [\n",
      "      222,\n",
      "      213,\n",
      "      180,\n",
      "      248\n",
      "    ]\n",
      "  },\n",
      "  \"tags\": [\n",
      "    \"diveintopython\",\n",
      "    \"docbook\",\n",
      "    \"html\"\n",
      "  ],\n",
      "  \"published\": true,\n",
      "  \"published_date\": {\n",
      "    \"__class__\": \"datetime.asctime\",\n",
      "    \"__value__\": \"21/11/06 16:30\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "with open('examples/entry.json', 'r') as f:\n",
    "    for line in f:\n",
    "        print(line.rstrip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loading data from a json file\n",
    "\n",
    "Like the `pickle` module the `json` module has a `load()` function which takes a stream object, reads JSON-encoded data from it and creates a new Python object that mirrors the JSON data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "del entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('examples/entry.json', 'r', encoding='utf-8') as f:\n",
    "    entry = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Dive into history, 2009 edition',\n",
       " 'article_link': 'http://diveintomark.org/archives/2009/03/27/dive-into-history-2009-edition',\n",
       " 'comments_link': None,\n",
       " 'internal_id': {'__class__': 'bytes', '__value__': [222, 213, 180, 248]},\n",
       " 'tags': ['diveintopython', 'docbook', 'html'],\n",
       " 'published': True,\n",
       " 'published_date': {'__class__': 'datetime.asctime',\n",
       "  '__value__': '21/11/06 16:30'}}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`json.loads()` does not know anything about any conversion function we used in the call to `json.dumps()`. We need a function that is the opposite of `to_json` - a function that will take a custom converted JSON object and convert it back to the python datatype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def from_json(json_object):\n",
    "    if '__class__' in json_object:\n",
    "        if json_object['__class__'] == 'bytes':\n",
    "            return bytes(json_object['__value__'])\n",
    "        \n",
    "        if json_object['__class__'] == 'datetime.asctime':\n",
    "            return datetime.strptime(json_object['__value__'], \n",
    "                                     \"%d/%m/%y %H:%M\")\n",
    "        \n",
    "    return json_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "del entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Dive into history, 2009 edition',\n",
       " 'article_link': 'http://diveintomark.org/archives/2009/03/27/dive-into-history-2009-edition',\n",
       " 'comments_link': None,\n",
       " 'internal_id': b'\\xde\\xd5\\xb4\\xf8',\n",
       " 'tags': ['diveintopython', 'docbook', 'html'],\n",
       " 'published': True,\n",
       " 'published_date': datetime.datetime(2006, 11, 21, 16, 30)}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('examples/entry.json', 'r', encoding='utf-8') as f:\n",
    "    entry = json.load(f, object_hook=from_json)\n",
    "    \n",
    "entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "entry"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
